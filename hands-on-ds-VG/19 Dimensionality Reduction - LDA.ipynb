{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
      "0     1    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
      "1     1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
      "2     1    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
      "3     1    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
      "4     1    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
      "\n",
      "   Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
      "0                  0.28     2.29       5.64  1.04  3.92     1065  \n",
      "1                  0.26     1.28       4.38  1.05  3.40     1050  \n",
      "2                  0.30     2.81       5.68  1.03  3.17     1185  \n",
      "3                  0.24     2.18       7.80  0.86  3.45     1480  \n",
      "4                  0.39     1.82       4.32  1.04  2.93      735  \n",
      "     Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
      "173     3    13.71        5.65  2.45  20.5   95     1.68        0.61   \n",
      "174     3    13.40        3.91  2.48  23.0  102     1.80        0.75   \n",
      "175     3    13.27        4.28  2.26  20.0  120     1.59        0.69   \n",
      "176     3    13.17        2.59  2.37  20.0  120     1.65        0.68   \n",
      "177     3    14.13        4.10  2.74  24.5   96     2.05        0.76   \n",
      "\n",
      "     Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
      "173                  0.52     1.06        7.7  0.64  1.74      740  \n",
      "174                  0.43     1.41        7.3  0.70  1.56      750  \n",
      "175                  0.43     1.35       10.2  0.59  1.56      835  \n",
      "176                  0.53     1.46        9.3  0.60  1.62      840  \n",
      "177                  0.56     1.35        9.2  0.61  1.60      560  \n",
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "\n",
    "dataset = pd.read_csv(\"wine.csv\")\n",
    "\n",
    "print(dataset.head())\n",
    "print(dataset.tail())\n",
    "\n",
    "# independent variables \n",
    "X = dataset.iloc[:, 1:14].values\n",
    "print(X)\n",
    "\n",
    "# dependent variable - type of whine (1, 2 or 3)\n",
    "y = dataset.iloc[:, 0].values\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13)\n",
      "(36, 13)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling on independent variables\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73931691 0.26068309]\n"
     ]
    }
   ],
   "source": [
    "# Applying LDA\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "\n",
    "X_train = lda.fit_transform(X_train, y_train)\n",
    "X_test = lda.transform(X_test)\n",
    "\n",
    "explained_variance = lda.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.57315552  1.94018924]\n",
      " [ 0.85475898 -2.08182977]\n",
      " [ 0.62173655 -3.06234453]\n",
      " [ 4.80786412  2.00638739]\n",
      " [-3.8579759   0.14987256]\n",
      " [-3.59455458  1.24961706]\n",
      " [-0.53772906 -3.0852704 ]\n",
      " [ 0.04058577 -2.47312446]\n",
      " [ 0.99835348 -3.36989668]\n",
      " [-3.74095658  1.94844242]\n",
      " [ 3.76035226  0.82126218]\n",
      " [-0.15106412 -1.86820292]\n",
      " [ 3.62762899  2.05460026]\n",
      " [-3.94229781  2.80328429]\n",
      " [ 3.33429017  0.73627798]\n",
      " [ 3.90206871  1.03276135]\n",
      " [-3.55835472  0.18783108]\n",
      " [ 5.63175281  2.40524214]\n",
      " [-5.56217254  0.85694946]\n",
      " [ 0.23296188 -3.94615581]\n",
      " [ 5.03141997  3.23313754]\n",
      " [ 3.52861651  0.94605778]\n",
      " [-1.17815662 -2.17294825]\n",
      " [ 3.58320131  0.67947364]\n",
      " [ 5.21649905  2.41090952]\n",
      " [-3.01647841  1.24411621]\n",
      " [ 1.86178658 -0.47484926]\n",
      " [ 3.93816398 -0.2204059 ]\n",
      " [-1.0836235  -3.32496762]\n",
      " [ 1.8691488  -0.63362283]\n",
      " [ 3.27717205  1.51263542]\n",
      " [-0.47842302 -1.16766723]\n",
      " [-4.14433134  1.37391708]\n",
      " [ 2.45009727 -2.49336285]\n",
      " [-1.20844631 -2.30679956]\n",
      " [ 2.55631466 -0.98550214]\n",
      " [-1.6091476   0.55066705]\n",
      " [-5.52462148  2.19178828]\n",
      " [-2.44685583 -2.28937848]\n",
      " [-1.95474568 -2.02963924]\n",
      " [ 5.54394234  1.5236766 ]\n",
      " [ 5.74409562  1.85156779]\n",
      " [ 1.13553056 -3.93865462]\n",
      " [-1.2483554  -3.08106324]\n",
      " [-0.00961488 -3.62708415]\n",
      " [ 5.21418108  2.66981962]\n",
      " [ 4.2290474   0.3886969 ]\n",
      " [-3.94237521  0.76214343]\n",
      " [ 5.30822458  2.18894363]\n",
      " [-0.20862902 -3.05785486]\n",
      " [ 0.47295413 -2.560251  ]\n",
      " [ 0.46692465 -1.86886738]\n",
      " [-1.05818513 -2.61576658]\n",
      " [ 0.33551985 -3.26643922]\n",
      " [-4.74777848  2.23081211]\n",
      " [-2.80968166  1.32816126]\n",
      " [-1.02804047 -2.60107642]\n",
      " [-6.15432728  2.12945198]\n",
      " [ 4.33944259  1.23494233]\n",
      " [-3.63172128  0.54074799]\n",
      " [ 4.79575236  1.25996976]\n",
      " [-4.13914056  0.36020476]\n",
      " [-3.94468876  3.0153646 ]\n",
      " [-0.42472714 -2.30200526]\n",
      " [-5.17777666  2.36899585]\n",
      " [-1.3044572  -2.87041347]\n",
      " [ 0.06991014 -2.78082083]\n",
      " [-4.98245326  3.83183665]\n",
      " [ 4.3064623   2.4129711 ]\n",
      " [ 0.29208614 -2.06937039]\n",
      " [-5.0934408   3.0899463 ]\n",
      " [ 0.61101399  0.17866792]\n",
      " [ 1.12081287 -2.87291369]\n",
      " [-0.77339273 -2.03777551]\n",
      " [ 2.57603424  0.08537633]\n",
      " [-4.29104423  2.28661799]\n",
      " [ 5.255722    0.61832811]\n",
      " [ 5.7318737   0.19267558]\n",
      " [-6.24884704  3.55128212]\n",
      " [-5.38587866  1.77559442]\n",
      " [ 1.31025756 -2.52845345]\n",
      " [ 5.00526015  2.31115606]\n",
      " [-4.31499585  1.99154644]\n",
      " [-3.92894005  2.13127776]\n",
      " [-0.05838671 -2.60549973]\n",
      " [-0.42566332 -1.68426706]\n",
      " [-3.5253992   0.16028802]\n",
      " [-4.42913323  2.47869828]\n",
      " [-2.85063973  1.1163819 ]\n",
      " [ 4.46460374  3.55045935]\n",
      " [-1.21751159 -1.31441447]\n",
      " [-4.94290391  1.29321013]\n",
      " [-1.70880192 -2.10638157]\n",
      " [ 3.42314438  1.21989584]\n",
      " [-5.58393165  2.49598525]\n",
      " [-0.71859407 -2.67293812]\n",
      " [ 4.01611408  0.13560479]\n",
      " [ 4.64009352 -0.06178578]\n",
      " [-3.85066489  1.66509736]\n",
      " [-3.47123425 -0.07349273]\n",
      " [ 4.17391188  0.51767626]\n",
      " [-4.09941682  3.11353194]\n",
      " [ 4.29592104  0.18486038]\n",
      " [-0.15570245 -3.78905263]\n",
      " [-3.29789207  1.48134709]\n",
      " [-4.0655232   1.02548943]\n",
      " [-0.63468603 -2.68007872]\n",
      " [-4.4641561   2.38128912]\n",
      " [ 4.52246935  1.96313747]\n",
      " [ 0.79712615 -3.04743012]\n",
      " [ 4.91056287  1.22473167]\n",
      " [-3.77150311  0.30882908]\n",
      " [ 3.5444653   1.05962644]\n",
      " [ 4.36398757  1.78816415]\n",
      " [ 4.86008035  2.32823762]\n",
      " [-3.46481941  1.07890379]\n",
      " [-1.65664035 -3.72251678]\n",
      " [ 0.26593072 -2.87995582]\n",
      " [-0.66345544 -2.36083579]\n",
      " [-0.33965319 -5.76922451]\n",
      " [ 5.14221842  1.93740967]\n",
      " [ 5.75746454  2.94776345]\n",
      " [ 0.42253477 -1.5887479 ]\n",
      " [ 0.96267148 -1.57482982]\n",
      " [-2.5640305   0.20647539]\n",
      " [-2.30398129 -1.49865287]\n",
      " [ 4.91741587  2.32620455]\n",
      " [ 5.20879938  2.96660159]\n",
      " [-3.60895143  2.468315  ]\n",
      " [-4.58647662  2.42583146]\n",
      " [ 2.89493473  1.15627605]\n",
      " [-0.09551518 -1.90444969]\n",
      " [ 1.30043304 -0.87538895]\n",
      " [ 0.16805348 -3.21257614]\n",
      " [-3.19016989  1.66680508]\n",
      " [-2.08858151  0.83647089]\n",
      " [-4.25960623  1.54637835]\n",
      " [ 1.68647094 -3.83427605]\n",
      " [-0.9020576  -2.62989337]\n",
      " [-0.19105618 -3.66017053]\n",
      " [-4.20632725  0.8310719 ]\n",
      " [ 4.52910794  3.07839306]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting logistic regression to training set\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2 1 2 2 1 3 2 2 3 3 1 2 3 2 1 1 2 1 2 1 1 2 2 2 2 2 2 3 1 1 2 1 1 1]\n",
      "[1 3 2 1 2 2 1 3 2 2 3 3 1 2 3 2 1 1 2 1 2 1 1 2 2 2 2 2 2 3 1 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predicting Test set results\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = (14 + 16 + 6)/36 * 100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
